{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12246593,"sourceType":"datasetVersion","datasetId":7716433}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Libs\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, Wav2Vec2Processor, Wav2Vec2Model, AutoModelForSeq2SeqLM\nfrom tqdm import tqdm\nimport os\nfrom datasets import load_dataset\nfrom IPython.display import Audio, display\nimport json","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-22T12:57:11.860094Z","iopub.execute_input":"2025-06-22T12:57:11.860720Z","iopub.status.idle":"2025-06-22T12:57:36.541816Z","shell.execute_reply.started":"2025-06-22T12:57:11.860695Z","shell.execute_reply":"2025-06-22T12:57:36.541269Z"}},"outputs":[{"name":"stderr","text":"2025-06-22 12:57:24.618949: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1750597044.796914      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1750597044.849587      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Configs\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T12:57:36.543038Z","iopub.execute_input":"2025-06-22T12:57:36.543586Z","iopub.status.idle":"2025-06-22T12:57:36.547381Z","shell.execute_reply.started":"2025-06-22T12:57:36.543566Z","shell.execute_reply":"2025-06-22T12:57:36.546655Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!git clone https://github.com/VarunGumma/IndicTransToolkit\n!pwd\n%cd IndicTransToolkit\n\n!python3 -m pip install --editable ./","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T12:57:36.548084Z","iopub.execute_input":"2025-06-22T12:57:36.548308Z","iopub.status.idle":"2025-06-22T12:59:10.557467Z","shell.execute_reply.started":"2025-06-22T12:57:36.548292Z","shell.execute_reply":"2025-06-22T12:59:10.556458Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Cloning into 'IndicTransToolkit'...\nremote: Enumerating objects: 245, done.\u001b[K\nremote: Counting objects: 100% (150/150), done.\u001b[K\nremote: Compressing objects: 100% (89/89), done.\u001b[K\nremote: Total 245 (delta 74), reused 108 (delta 49), pack-reused 95 (from 1)\u001b[K\nReceiving objects: 100% (245/245), 4.45 MiB | 23.24 MiB/s, done.\nResolving deltas: 100% (102/102), done.\n/kaggle/working\n/kaggle/working/IndicTransToolkit\nObtaining file:///kaggle/working/IndicTransToolkit\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.11/dist-packages (from IndicTransToolkit==1.0.4) (75.2.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from IndicTransToolkit==1.0.4) (2.6.0+cu124)\nRequirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from IndicTransToolkit==1.0.4) (3.0.12)\nCollecting sacremoses (from IndicTransToolkit==1.0.4)\n  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from IndicTransToolkit==1.0.4) (0.2.0)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from IndicTransToolkit==1.0.4) (4.51.3)\nCollecting sacrebleu (from IndicTransToolkit==1.0.4)\n  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting indic-nlp-library-itt (from IndicTransToolkit==1.0.4)\n  Downloading indic_nlp_library_itt-0.1.0-py3-none-any.whl.metadata (2.1 kB)\nCollecting morfessor<3.0.0,>=2.0.6 (from indic-nlp-library-itt->IndicTransToolkit==1.0.4)\n  Downloading Morfessor-2.0.6-py3-none-any.whl.metadata (628 bytes)\nCollecting numpy<3.0.0,>=2.2.5 (from indic-nlp-library-itt->IndicTransToolkit==1.0.4)\n  Downloading numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (62 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pandas<3.0.0,>=2.2.3 in /usr/local/lib/python3.11/dist-packages (from indic-nlp-library-itt->IndicTransToolkit==1.0.4) (2.2.3)\nCollecting sphinx-argparse<0.6.0,>=0.5.2 (from indic-nlp-library-itt->IndicTransToolkit==1.0.4)\n  Downloading sphinx_argparse-0.5.2-py3-none-any.whl.metadata (3.7 kB)\nCollecting sphinx-rtd-theme<4.0.0,>=3.0.2 (from indic-nlp-library-itt->IndicTransToolkit==1.0.4)\n  Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl.metadata (4.4 kB)\nCollecting portalocker (from sacrebleu->IndicTransToolkit==1.0.4)\n  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu->IndicTransToolkit==1.0.4) (2024.11.6)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu->IndicTransToolkit==1.0.4) (0.9.0)\nRequirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu->IndicTransToolkit==1.0.4) (0.4.6)\nRequirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu->IndicTransToolkit==1.0.4) (5.3.1)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sacremoses->IndicTransToolkit==1.0.4) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from sacremoses->IndicTransToolkit==1.0.4) (1.5.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sacremoses->IndicTransToolkit==1.0.4) (4.67.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.4) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.4) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.4) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.4) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.4) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.4) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.4) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.4) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch->IndicTransToolkit==1.0.4)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch->IndicTransToolkit==1.0.4)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch->IndicTransToolkit==1.0.4)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch->IndicTransToolkit==1.0.4)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch->IndicTransToolkit==1.0.4)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch->IndicTransToolkit==1.0.4)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.4) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.4) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.4) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch->IndicTransToolkit==1.0.4)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.4) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.4) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->IndicTransToolkit==1.0.4) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers->IndicTransToolkit==1.0.4) (0.31.1)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers->IndicTransToolkit==1.0.4) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers->IndicTransToolkit==1.0.4) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers->IndicTransToolkit==1.0.4) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->IndicTransToolkit==1.0.4) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers->IndicTransToolkit==1.0.4) (0.5.3)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers->IndicTransToolkit==1.0.4) (1.1.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=2.2.3->indic-nlp-library-itt->IndicTransToolkit==1.0.4) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=2.2.3->indic-nlp-library-itt->IndicTransToolkit==1.0.4) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=2.2.3->indic-nlp-library-itt->IndicTransToolkit==1.0.4) (2025.2)\nRequirement already satisfied: sphinx>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from sphinx-argparse<0.6.0,>=0.5.2->indic-nlp-library-itt->IndicTransToolkit==1.0.4) (8.2.3)\nRequirement already satisfied: docutils>=0.19 in /usr/local/lib/python3.11/dist-packages (from sphinx-argparse<0.6.0,>=0.5.2->indic-nlp-library-itt->IndicTransToolkit==1.0.4) (0.21.2)\nCollecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme<4.0.0,>=3.0.2->indic-nlp-library-itt->IndicTransToolkit==1.0.4)\n  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->IndicTransToolkit==1.0.4) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->IndicTransToolkit==1.0.4) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->IndicTransToolkit==1.0.4) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->IndicTransToolkit==1.0.4) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->IndicTransToolkit==1.0.4) (2025.4.26)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.2.3->indic-nlp-library-itt->IndicTransToolkit==1.0.4) (1.17.0)\nRequirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse<0.6.0,>=0.5.2->indic-nlp-library-itt->IndicTransToolkit==1.0.4) (2.0.0)\nRequirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse<0.6.0,>=0.5.2->indic-nlp-library-itt->IndicTransToolkit==1.0.4) (2.0.0)\nRequirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse<0.6.0,>=0.5.2->indic-nlp-library-itt->IndicTransToolkit==1.0.4) (2.1.0)\nRequirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse<0.6.0,>=0.5.2->indic-nlp-library-itt->IndicTransToolkit==1.0.4) (1.0.1)\nRequirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse<0.6.0,>=0.5.2->indic-nlp-library-itt->IndicTransToolkit==1.0.4) (2.0.0)\nRequirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse<0.6.0,>=0.5.2->indic-nlp-library-itt->IndicTransToolkit==1.0.4) (2.0.0)\nRequirement already satisfied: Pygments>=2.17 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse<0.6.0,>=0.5.2->indic-nlp-library-itt->IndicTransToolkit==1.0.4) (2.19.1)\nRequirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse<0.6.0,>=0.5.2->indic-nlp-library-itt->IndicTransToolkit==1.0.4) (2.2.0)\nRequirement already satisfied: babel>=2.13 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse<0.6.0,>=0.5.2->indic-nlp-library-itt->IndicTransToolkit==1.0.4) (2.17.0)\nRequirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse<0.6.0,>=0.5.2->indic-nlp-library-itt->IndicTransToolkit==1.0.4) (1.0.0)\nRequirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse<0.6.0,>=0.5.2->indic-nlp-library-itt->IndicTransToolkit==1.0.4) (1.4.1)\nRequirement already satisfied: roman-numerals-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse<0.6.0,>=0.5.2->indic-nlp-library-itt->IndicTransToolkit==1.0.4) (3.1.0)\nDownloading indic_nlp_library_itt-0.1.0-py3-none-any.whl (54 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\nDownloading numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl (16.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading sphinx_argparse-0.5.2-py3-none-any.whl (12 kB)\nDownloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl (7.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\nDownloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: IndicTransToolkit\n  Building editable for IndicTransToolkit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for IndicTransToolkit: filename=indictranstoolkit-1.0.4-0.editable-cp311-cp311-linux_x86_64.whl size=6482 sha256=00969608c506a774f37dcd0ce0f40060cbc3ff3a42871620a4f379764897f107\n  Stored in directory: /tmp/pip-ephem-wheel-cache-2di93i5f/wheels/bd/1b/cb/0d237bb93d15ee989dacca86ebfc57098fcea498af4b6e5ff4\nSuccessfully built IndicTransToolkit\nInstalling collected packages: morfessor, sacremoses, portalocker, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, numpy, sacrebleu, nvidia-cusparse-cu12, nvidia-cudnn-cu12, sphinxcontrib-jquery, sphinx-argparse, nvidia-cusolver-cu12, sphinx-rtd-theme, indic-nlp-library-itt, IndicTransToolkit\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.4\n    Uninstalling numpy-1.26.4:\n      Successfully uninstalled numpy-1.26.4\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n  Attempting uninstall: sphinx-rtd-theme\n    Found existing installation: sphinx-rtd-theme 0.2.4\n    Uninstalling sphinx-rtd-theme-0.2.4:\n      Successfully uninstalled sphinx-rtd-theme-0.2.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.3.1 which is incompatible.\ngensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.2 which is incompatible.\nmkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.1 which is incompatible.\nmkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.1 which is incompatible.\nmkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.1 which is incompatible.\ncupy-cuda12x 13.4.1 requires numpy<2.3,>=1.22, but you have numpy 2.3.1 which is incompatible.\nnumba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.1 which is incompatible.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\nydata-profiling 4.16.1 requires numpy<2.2,>=1.16.0, but you have numpy 2.3.1 which is incompatible.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\npreprocessing 0.1.13 requires sphinx-rtd-theme==0.2.4, but you have sphinx-rtd-theme 3.0.2 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.1 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\ntensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.3.1 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed IndicTransToolkit-1.0.4 indic-nlp-library-itt-0.1.0 morfessor-2.0.6 numpy-2.3.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 portalocker-3.2.0 sacrebleu-2.5.1 sacremoses-0.1.1 sphinx-argparse-0.5.2 sphinx-rtd-theme-3.0.2 sphinxcontrib-jquery-4.1\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pwd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T12:59:10.559391Z","iopub.execute_input":"2025-06-22T12:59:10.559649Z","iopub.status.idle":"2025-06-22T12:59:10.701656Z","shell.execute_reply.started":"2025-06-22T12:59:10.559623Z","shell.execute_reply":"2025-06-22T12:59:10.700774Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/IndicTransToolkit\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from IndicTransToolkit.processor import IndicProcessor\n%cd ..","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T12:59:10.702915Z","iopub.execute_input":"2025-06-22T12:59:10.703161Z","iopub.status.idle":"2025-06-22T12:59:10.992397Z","shell.execute_reply.started":"2025-06-22T12:59:10.703135Z","shell.execute_reply":"2025-06-22T12:59:10.991651Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Complete multimodal punctuation training script\n\nPUNCT_LABELS = {\"O\": 0, \",\": 1, \".\": 2, \"?\": 3, \";\": 4}  # No punct, comma, period, question, semicolon\n\n# ---------------------- Dataset ---------------------- #\n\nclass FleursPunctuationDataset(Dataset):\n    def __init__(self, alignment_jsonl, tokenizer_name, indictrans_name, wav2vec_name):\n        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)\n        # self.wav2vec_processor = Wav2Vec2Processor.from_pretrained(wav2vec_name, trust_remote_code=True)\n        # self.wav2vec_model = Wav2Vec2Model.from_pretrained(wav2vec_name, trust_remote_code=True).to(device).eval()\n        w2v_temp = torch.load('/kaggle/input/w2v_feats/w2v_train_output.pt')\n        self.w2v_features = {item[\"id\"]: item[\"feature\"] for item in w2v_temp}\n        # self.indic_encoder = AutoModelForSeq2SeqLM.from_pretrained(indictrans_name, trust_remote_code=True, torch_dtype=torch.float16, attn_implementation=\"flash_attention_2\").to(device).eval()\n        indic_temp = torch.load('/kaggle/input/indic_feats/indictrans_enc_unpunct_fleurs_train.pt')\n        self.indic_features = {item[\"id\"]: item[\"encoded_vector\"] for item in indic_temp}\n\n        with open(alignment_jsonl, 'r') as f:\n            alignment_lines = [json.loads(line) for line in f]\n            self.ids = [line['id'] for line in alignment_lines]\n            self.alignments = {line['id']: line['words'] for line in alignment_lines}\n\n        from datasets import load_dataset\n        fleurs = load_dataset(\"google/fleurs\", \"en_us\", split=\"train\", trust_remote_code=True)\n        self.data = {}\n        for example in fleurs:\n            if example['id'] in self.ids:\n                self.data[example['id']] = {\n                    'id': example['id'],\n                    # 'audio': example['audio']['array'],\n                    'w2v_feat': self.w2v_features[example['id']],\n                    'indic_feat': self.indic_features[example['id']],\n                    'text': example['transcription'].strip(),\n                    'raw_text': example['raw_transcription'].strip()\n                }\n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, idx):\n        audio_id = self.ids[idx]\n        entry = self.data[audio_id]\n        # waveform = torch.tensor(entry['audio']).unsqueeze(0)\n        # sr = 16000  # [1, T]\n\n        # # Extract acoustic features using wav2vec2\n        # with torch.no_grad():\n        #     input_values = self.wav2vec_processor(waveform.squeeze(0).numpy(), sampling_rate=sr, return_tensors=\"pt\", padding=True).input_values.to(device)\n        #     acoustic_hidden = self.wav2vec_model(input_values).last_hidden_state[0]  # [T', 768]\n        # acoustic_feats = acoustic_hidden.cpu()  # [T', D]\n\n        # Extract lexical features using indictrans2\n        with torch.no_grad():\n            text_input = self.tokenizer(entry['text'], return_tensors=\"pt\").to(device)\n            text_feats = self.indic_encoder(**text_input).last_hidden_state[0]  # [L, D]\n\n        input_ids = text_input['input_ids'][0]\n        tokens = self.tokenizer.convert_ids_to_tokens(input_ids)\n        punct_targets = self.get_punctuation_labels(entry['raw_text'], tokens)\n\n        word_times = [(w['start'], w['end']) for w in self.alignments[audio_id]]\n\n        return {\n            'id': audio_id,\n            'text_tokens': input_ids,\n            'punct_labels': punct_targets,\n            'text_feats': text_feats.cpu(),\n            'audio_feats': entry['w2v_feat'].cpu(),\n            'word_times': word_times,\n        }\n\n    def get_punctuation_labels(self, raw_text, tokens):\n        labels = []\n        punct_map = {\".\": \".\", \",\": \",\", \"?\": \"?\", \";\": \";\"}\n        text = raw_text.replace(\"\\u2019\", \"'\")\n        words = text.split()\n        i = 0\n        for tok in tokens:\n            if tok.startswith(\"▁\"):\n                label = \"O\"\n                if i < len(words) and words[i][-1] in punct_map:\n                    label = punct_map[words[i][-1]]\n                    words[i] = words[i][:-1]\n                i += 1\n            else:\n                label = \"O\"\n            labels.append(PUNCT_LABELS[label])\n        return torch.tensor(labels, dtype=torch.long)\n\n\n# ------------------- Acoustic Encoder ------------------- #\n\nclass AcousticEncoder(nn.Module):\n    def __init__(self, input_dim=768, conv_out_dim=1024, lstm_hidden=1024):\n        super().__init__()\n        self.conv1d = nn.Conv1d(in_channels=input_dim, out_channels=conv_out_dim, kernel_size=5, padding=2)\n        self.lstm = nn.LSTM(input_size=conv_out_dim, hidden_size=lstm_hidden, batch_first=True)\n\n    def forward(self, features):\n        features = features.transpose(1, 2)  # [B, D, T]\n        conv_out = self.conv1d(features)     # [B, C, T]\n        conv_out = conv_out.transpose(1, 2)  # [B, T, C]\n        lstm_out, _ = self.lstm(conv_out)    # [B, T, H]\n        return lstm_out\n\n# ------------------- Punctuation Model ------------------- #\n\nclass PunctuationModel(nn.Module):\n    def __init__(self, text_dim, audio_dim, hidden_dim=1024, num_classes=5):\n        super().__init__()\n        self.fuse = nn.Linear(text_dim + audio_dim, num_classes)\n\n    def forward(self, text_feats, audio_feats):\n        fused = torch.cat([text_feats, audio_feats], dim=-1)\n        logits = self.fuse(fused)\n        return logits\n\n\n# ---------------------- Training Loop ---------------------- #\n\ndef train(model, dataloader, optimizer, num_epochs):\n    model.train()\n    loss_fn = nn.CrossEntropyLoss()\n    for epoch in range(num_epochs):\n        total_loss = 0\n        for batch in tqdm(dataloader):\n            input_ids = batch['text_tokens']\n            text_feats = torch.stack(batch['text_feats']).to(device)\n            audio_feats = align_audio_to_tokens(batch, text_feats.size(1)).to(device)\n            labels = torch.stack(batch['punct_labels']).to(device)\n\n            audio_encoded = model[0](audio_feats.unsqueeze(0)).squeeze(0)\n            logits = model[1](text_feats, audio_encoded)\n            loss = loss_fn(logits.view(-1, logits.size(-1)), labels.view(-1))\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n        print(f\"Epoch {epoch+1} Loss: {total_loss/len(dataloader):.4f}\")\n\n\n# ---------------------- Audio Alignment ---------------------- #\n\ndef align_audio_to_tokens(batch, L):\n    aligned_batch = []\n    for b in range(len(batch['audio_feats'])):\n        frame_feats = batch['audio_feats'][b]  # [T', D]\n        word_times = batch['word_times'][b]\n        word_feats = []\n        for start, end in word_times:\n            start_idx = int(start * 50)\n            end_idx = int(end * 50)\n            pooled = frame_feats[end_idx - 1] if end_idx > start_idx else frame_feats[start_idx]\n            word_feats.append(pooled)\n\n        aligned_feats = []\n        word_ptr = 0\n        tokens = batch['text_tokens'][b]\n        for tok in tokens:\n            if tok.item() >= 0 and tokenizer.convert_ids_to_tokens([tok])[0].startswith(\"▁\"):\n                aligned_feats.append(word_feats[word_ptr])\n                word_ptr += 1\n            else:\n                aligned_feats.append(word_feats[word_ptr-1])\n        aligned_tensor = torch.stack(aligned_feats, dim=0)\n        aligned_batch.append(aligned_tensor)\n    return torch.stack(aligned_batch, dim=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T12:59:10.993249Z","iopub.execute_input":"2025-06-22T12:59:10.994055Z","iopub.status.idle":"2025-06-22T12:59:11.013505Z","shell.execute_reply.started":"2025-06-22T12:59:10.994033Z","shell.execute_reply":"2025-06-22T12:59:11.012752Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# ---------------------- Example Usage ---------------------- #\n\nALIGNMENT_JSONL = '/kaggle/input/fleurs-alignment/alignment_output_cleaned_deduplicated.jsonl'\nTOKENIZER = 'ai4bharat/indictrans2-indic-en-1B'\nINDIC_MODEL = 'ai4bharat/indictrans2-indic-en-1B'\nW2V_MODEL = 'facebook/wav2vec2-base-960h'\n\ndataset = FleursPunctuationDataset(ALIGNMENT_JSONL, TOKENIZER, INDIC_MODEL, W2V_MODEL)\ndataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=lambda x: {k: [d[k] for d in x] for k in x[0]})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T12:59:11.014317Z","iopub.execute_input":"2025-06-22T12:59:11.014535Z","iopub.status.idle":"2025-06-22T13:01:02.432644Z","shell.execute_reply.started":"2025-06-22T12:59:11.014518Z","shell.execute_reply":"2025-06-22T13:01:02.432045Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.10k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5cb85070b68451ba6652281f055b65a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenization_indictrans.py:   0%|          | 0.00/8.04k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"695ea9106339460c93ee5d4b1e698db9"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-indic-en-1B:\n- tokenization_indictrans.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"dict.SRC.json:   0%|          | 0.00/3.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9e721918ff04506bc73768b0bf03851"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dict.TGT.json:   0%|          | 0.00/645k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"204f442c7b1545a48c1ca6e83cdf080b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.SRC:   0%|          | 0.00/3.26M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb0788717c24487daf177d977df578ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.TGT:   0%|          | 0.00/759k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16d366e7fbb5474dac4be444c1730268"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/96.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ed7ebc242a6464db339f961060dc292"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e611c0ba2e1343bf8d8e576467609789"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b54ec4bc15664df1b946a89210c2d6f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"222c70aae93e4ab48ded0391a8db88a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1deb28b934ea47f4848bf117b0387078"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d1655ff463246b0996f3f7ba355b8ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/378M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"082f88664e014946a200a8b7099f4eab"}},"metadata":{}},{"name":"stderr","text":"Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['masked_spec_embed']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.37k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1f2047adf2d425cbcfd6a497ad8fa16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_indictrans.py:   0%|          | 0.00/14.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab3c1a3a8e3e441aa81e46607256e8f5"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-indic-en-1B:\n- configuration_indictrans.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_indictrans.py:   0%|          | 0.00/79.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85fafa8437ec4f6f98068c7a463bfe1f"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-indic-en-1B:\n- modeling_indictrans.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/4.09G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a8a4b5ff99e4149afdd35dfa86c60fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e40b5afecec47748f51e0edaae4e478"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/13.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35b4264b6f4c42fda0aeaf342095bf99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"fleurs.py:   0%|          | 0.00/12.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e12a4a3d106f48649dcb9e7e53bc29ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train.tar.gz:   0%|          | 0.00/1.38G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc3fc22395ce438cb2fb5bd3d7971152"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dev.tar.gz:   0%|          | 0.00/171M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18669c670c40472b92a69b45bd570ec5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test.tar.gz:   0%|          | 0.00/290M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"021d366c27ba49e2a01e9c690b8e8a85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train.tsv:   0%|          | 0.00/1.41M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d598128b82e440c790bf9ce7060871c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dev.tsv:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c13387d7096743128d012485a7c7fcf5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test.tsv:   0%|          | 0.00/368k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"def75db48f594aeaac89df98fb02fbb5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12712d899d3d4d34b95fb253979b7df9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b1aa35ee3204afaa5fea9e30296e134"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7600f2d76b29485e8e4f6d6b0d17539a"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"acoustic_encoder = AcousticEncoder().to(device)\nmodel = nn.Sequential(\n    acoustic_encoder,\n    PunctuationModel(text_dim=1024, audio_dim=1024)\n).to(device)\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=2e-4)\n\nfor name, param in model.named_parameters():\n    if 'proj_audio' not in name and 'fuse' not in name and 'context' not in name and 'classifier' not in name:\n        param.requires_grad = False\n\ntrain(model, dataloader, optimizer, num_epochs=5)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}